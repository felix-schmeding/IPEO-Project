{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS is a jupyter notebook named inference.ipynb that \\\n",
    "a. loads at least one image/sample from the test set \\ \n",
    "b. loads trained parameters from the best model you trained \\\n",
    "c. runs inference (i.e. applies the model) on one image from the test set \\\n",
    "d. displays the predicJons for this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.CanopyDataset import CanopyDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aba8c0eac749a3bb5ba7342491e3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='train_idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# * To get an overview of training set and to visualize all bands + label\n",
    "\n",
    "# plot individual samples from train set\n",
    "val_df = CanopyDataset(split='validation')\n",
    "#train_df = CanopyDataset(split='train', transforms=None)\n",
    "\n",
    "from ipywidgets import interact\n",
    "@interact(train_idx=range(len(val_df)))\n",
    "def plot_sample(train_idx=0):\n",
    "    train_img, train_label = val_df[train_idx]\n",
    "    if torch.is_tensor(train_img):\n",
    "        train_img = train_img.numpy()\n",
    "        train_img = np.transpose(train_img, (1, 2, 0))\n",
    "    print(train_img.shape)\n",
    "\n",
    "    f, axs = plt.subplots(2,6, figsize=(14,4), constrained_layout=True)\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i in range(12):\n",
    "        sel = np.zeros(12, dtype=bool)\n",
    "        sel[i] = True\n",
    "        axs[i].imshow(train_img.compress(sel, axis=2))\n",
    "        axs[i].set_title(f\"Band {i}, index {train_idx}\")\n",
    "\n",
    "    f, ax = plt.subplots(1,1, figsize=(3,3))\n",
    "    ax.imshow(train_label)\n",
    "    ax.set_title(\"Label image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training model\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataset = train_df = CanopyDataset(split='train')\n",
    "\n",
    "# # TODO create a training data dataloader with the specifications above\n",
    "# train_dl = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=1)    \t# or num_workers = 2?\n",
    "# for image, label in train_dl:\n",
    "#   print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "# * to be implemented in a seperate file\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch import nn\n",
    "\n",
    "def setup_optimiser(model, learning_rate, weight_decay):\n",
    "  return SGD(\n",
    "    model.parameters(),\n",
    "    learning_rate,\n",
    "    weight_decay\n",
    "  )\n",
    "\n",
    "from tqdm.notebook import trange      # pretty progress bar\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()   # ! need to change\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_epoch(data_loader, model, optimiser, device):\n",
    "\n",
    "  # set model to training mode. This is important because some layers behave differently during training and testing\n",
    "  model.train(True)\n",
    "  model.to(device)\n",
    "\n",
    "  # stats\n",
    "  loss_total = 0.0\n",
    "  oa_total = 0.0\n",
    "\n",
    "  # iterate over dataset\n",
    "  pBar = trange(len(data_loader))\n",
    "  for idx, (data, target) in enumerate(data_loader):\n",
    "    # put data and target onto correct device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    # ! change to dataloader or dataset\n",
    "    data = data.to(torch.float32)   # to match weights of model\n",
    "    target = target.to(torch.float32) # to match data of model\n",
    "\n",
    "    # reset gradients\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    pred = model(data)\n",
    "\n",
    "    # loss\n",
    "    loss = criterion(pred, target)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameter update\n",
    "    optimiser.step()\n",
    "\n",
    "    # stats update\n",
    "    loss_total += loss.item()\n",
    "    # ! probably need to change\n",
    "    acc = torch.mean(torch.abs(torch.sub(pred, target))).item()\n",
    "    oa_total += acc\n",
    "\n",
    "    # format progress bar\n",
    "    pBar.set_description('Loss: {:.2f}, OA: {:.2f}'.format(\n",
    "      loss_total/(idx+1),\n",
    "      100 * oa_total/(idx+1)\n",
    "    ))\n",
    "    pBar.update(1)\n",
    "  \n",
    "  pBar.close()\n",
    "\n",
    "  # normalise stats\n",
    "  loss_total /= len(data_loader)\n",
    "  oa_total /= len(data_loader)\n",
    "\n",
    "  return model, loss_total, oa_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(data_loader, model, device):       # note: no optimiser needed\n",
    "\n",
    "  # set model to evaluation mode\n",
    "  model.train(False)\n",
    "  model.to(device)\n",
    "\n",
    "  # stats\n",
    "  loss_total = 0.0\n",
    "  oa_total = 0.0\n",
    "\n",
    "  # iterate over dataset\n",
    "  pBar = trange(len(data_loader))\n",
    "  for idx, (data, target) in enumerate(data_loader):\n",
    "    with torch.no_grad():\n",
    "\n",
    "      #TODO: likewise, implement the validation routine. This is very similar, but not identical, to the training steps.\n",
    "\n",
    "      # put data and target onto correct device\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      # ! change to dataloader or dataset\n",
    "      data = data.to(torch.float32)   # to match weights of model\n",
    "      target = target.to(torch.float32) # to match data of model\n",
    "\n",
    "      # forward pass\n",
    "      pred = model(data)\n",
    "\n",
    "      # loss\n",
    "      loss = criterion(pred, target)\n",
    "\n",
    "      # stats update\n",
    "      loss_total += loss.item()\n",
    "      acc = torch.mean(torch.abs(torch.sub(pred, target))).item()\n",
    "      oa_total += acc\n",
    "\n",
    "      # format progress bar\n",
    "      pBar.set_description('Loss: {:.2f}, OA: {:.2f}'.format(\n",
    "        loss_total/(idx+1),\n",
    "        100 * oa_total/(idx+1)\n",
    "      ))\n",
    "      pBar.update(1)\n",
    "\n",
    "  pBar.close()\n",
    "\n",
    "  # normalise stats\n",
    "  loss_total /= len(data_loader)\n",
    "  oa_total /= len(data_loader)\n",
    "\n",
    "  return loss_total, oa_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! --------------------------\n",
    "# model to test, copy paste back when working\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def residual(in_chan, out_channel):\n",
    "    # ! missing the 1x1 conv addition\n",
    "\n",
    "    residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=in_chan),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_chan, out_channel, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    return residual\n",
    "\n",
    "def residual_maxpool(in_chan, out_channel):\n",
    "    res_max = nn.Sequential(\n",
    "        residual(in_chan, out_channel),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "    )\n",
    "\n",
    "    return res_max\n",
    "\n",
    "def residual_decode(in_chan, out_channel):\n",
    "    residual = nn.Sequential(\n",
    "            # nn.MaxUnpool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(num_features=in_chan),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_chan, out_channel, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    return residual\n",
    "\n",
    "\n",
    "class SIDE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # super(self, SIDE).__init__() for backward compatiility\n",
    "\n",
    "        self.residualAdapt = residual(12, 64)\n",
    "        # seperate as we need the result for the forward pass\n",
    "        self.first_maxpool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        self.residual1 = residual_maxpool(64, 128)\n",
    "\n",
    "        # ! skip other ones, decode from 8 by 8\n",
    "\n",
    "\n",
    "        # * Upsampling\n",
    "\n",
    "        # unpool needs additionnal arg (indices), so seperate from residual block\n",
    "        # nn.Sequential doesn't allow for additional params\n",
    "        # https://stackoverflow.com/questions/59912850/autoencoder-maxunpool2d-missing-indices-argument\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.up1 = residual_decode(128, 64)\n",
    "        # maxunpool, \n",
    "        self.unpool2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        # need element wise sum in forward before last residual block\n",
    "        self.final = residual_decode(64, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residualAdapt(x)     # get from 12 to 64 channels\n",
    "        # print(\"shape after resadapt : \" + str(x.shape))\n",
    "        x1, ind1 = self.first_maxpool(x)    # first maxpool to 16x16x128\n",
    "        # print(\"shape after first_maxpool : \" + str(x1.shape))\n",
    "        x1, ind2 = self.residual1(x1)        # to 8x8x256\n",
    "        # print(\"shape after res1 : \" + str(x1.shape))\n",
    "        x1 = self.unpool1(x1, ind2)    # ind 2 as they are the last ones\n",
    "        # print(\"shape after unpool 1 : \" + str(x1.shape))\n",
    "        x1 = self.up1(x1)\n",
    "        # print(\"shape after up1 : \" + str(x1.shape))\n",
    "        x1 = self.unpool2(x1, ind1)\n",
    "        # print(\"shape after unpool2 : \" + str(x1.shape))\n",
    "\n",
    "        x = torch.add(x, x1)\n",
    "        x = self.final(x)\n",
    "\n",
    "        # need to get 32x32 tensor to compare to label\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# we also create a function for the data loader here (see Section 2.6 in Exercise 6)\n",
    "def load_dataloader(batch_size, dataset, split='train'):\n",
    "  return DataLoader(\n",
    "      dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=(split=='train'),       # we shuffle the image order for the training dataset\n",
    "      num_workers=2                   # perform data loading with two CPU threads\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! ------------------ model saving/loading\n",
    "\n",
    "import glob\n",
    "import os\n",
    "#from src.models.SIDE_code_decode import SIDE\n",
    "\n",
    "os.makedirs('cnn_states/SIDE', exist_ok=True)\n",
    "\n",
    "def load_model(epoch='latest'):\n",
    "  model = SIDE()\n",
    "  modelStates = glob.glob('cnn_states/SIDE/*.pth')\n",
    "  if len(modelStates) and (epoch == 'latest' or epoch > 0):\n",
    "    modelStates = [int(m.replace('cnn_states/SIDE/','').replace('.pth', '')) for m in modelStates]\n",
    "    if epoch == 'latest':\n",
    "      epoch = max(modelStates)\n",
    "    stateDict = torch.load(open(f'cnn_states/SIDE/{epoch}.pth', 'rb'), map_location='cpu')  # selects wieghts from epoch\n",
    "    model.load_state_dict(stateDict)\n",
    "  else:\n",
    "    # fresh model\n",
    "    epoch = 0       # no loaded weights\n",
    "  return model, epoch\n",
    "\n",
    "\n",
    "def save_model(model, epoch):\n",
    "  torch.save(model.state_dict(), open(f'cnn_states/SIDE/{epoch}.pth', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.models.SIDE_code_decode import SIDE\n",
    "\n",
    "# define hyperparameters\n",
    "device = 'cuda'\n",
    "start_epoch = 0        # set to 0 to start from scratch again or to 'latest' to continue training from saved checkpoint\n",
    "batch_size = 2\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# * create all the needed variables\n",
    "train_test_df = CanopyDataset(split='train')\n",
    "val_test_df = CanopyDataset(split='validation')\n",
    "\n",
    "# dataloader\n",
    "dl_train_test = load_dataloader(batch_size, train_test_df)\n",
    "dl_val_test = load_dataloader(batch_size, val_test_df)\n",
    "\n",
    "# model\n",
    "model_test = SIDE()\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optim_test = setup_optimiser(model_test, learning_rate, weight_decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only one step\n",
    "# model = model_test\n",
    "# data_loader = dl_train_test\n",
    "# optimiser = optim_test\n",
    "\n",
    "# model.train(True)\n",
    "# model.to(device)\n",
    "\n",
    "# # stats\n",
    "# loss_total = 0.0\n",
    "# oa_total = 0.0\n",
    "\n",
    "# for idx, (data, target) in enumerate(data_loader):\n",
    "#     # put data and target onto correct device\n",
    "#     data, target = data.to(device), target.to(device)\n",
    "#     # ! change to dataloader or dataset\n",
    "#     data = data.to(torch.float32)   # to match weights of model\n",
    "#     target = target.to(torch.float32) # to match data of model\n",
    "\n",
    "#     # reset gradients\n",
    "#     optimiser.zero_grad()\n",
    "\n",
    "#     # forward pass\n",
    "#     pred = model(data)\n",
    "\n",
    "#     # loss\n",
    "#     loss = criterion(pred, target)\n",
    "#     #print(str(type(loss)) + '  :  ' + str(loss.dtype)+ '  :  ' + str(loss.shape))\n",
    "#     #print(loss)\n",
    "\n",
    "#     # backward pass\n",
    "#     loss.backward()\n",
    "\n",
    "#     # parameter update\n",
    "#     optimiser.step()\n",
    "\n",
    "#     # stats update\n",
    "#     loss_total += loss.item()\n",
    "#     # mean of absolute per pixel height differences from predicted height and GT\n",
    "#     acc = torch.mean(torch.abs(torch.sub(pred, target))).item()\n",
    "#     oa_total += acc\n",
    "#     print('OA : ' + str(acc))\n",
    "\n",
    "#     #to do only 1 to test\n",
    "#     if idx > 20:\n",
    "#         break\n",
    "    \n",
    "\n",
    "# # normalise stats\n",
    "# loss_total /= len(data_loader)\n",
    "# oa_total /= len(data_loader)\n",
    "# print('totals:')\n",
    "# print(loss_total)\n",
    "# print(oa_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1191f0a41884a2981ddc34bb9ff9a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b9d9aedfc24f0f8503dac03787d3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\miniconda3\\envs\\IPEO\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1, 32, 32])) that is different to the input size (torch.Size([32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 1/10] Loss train: 1296.33, val: 19394.41; OA train: 1480.65, val: 5469.28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e426e121d79b4fce8782c4ba2f930872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89975e0988c64583afac38317d4f0ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 2/10] Loss train: 1129.77, val: 40627.32; OA train: 1344.81, val: 5703.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101d49ee818d4a0188c711407262fcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b5f83c4659415cb9d59c0ea8e687d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 3/10] Loss train: 1007.23, val: 12868.43; OA train: 1249.98, val: 5792.07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e378037d9374f1898aacf6739998ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcd0cd719b64dd8b14406b8ff3ef9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 4/10] Loss train: 925.22, val: 13071.39; OA train: 1123.39, val: 5627.92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c268b87f8344d4a688b9588224a47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f90742e4e2d4b50b00d1fcafc3283bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 5/10] Loss train: 876.82, val: 12725.88; OA train: 1039.07, val: 5720.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8111246e4ee4e00ab0d3f3afc203ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5829ffd2114e4693b1277b6f71021ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 6/10] Loss train: 839.53, val: 11660.61; OA train: 1013.57, val: 5431.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edde9060f48f4300a9909eda407b4722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028df700c47141d689e62f49d96f68e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 7/10] Loss train: 835.98, val: 15642.21; OA train: 1008.62, val: 5248.06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f76f7b3ec3d4b80af013479962c33b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345a2a9f04244b7681cd509b110be739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 8/10] Loss train: 826.55, val: 15609.61; OA train: 997.94, val: 5183.91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5826d3df9f1d48e4a5e7ca70b87c4794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f534cac7444d7e85c8341e2b763090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 9/10] Loss train: 816.55, val: 16475.44; OA train: 993.85, val: 5081.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0dcbcb15554d2982261c6417ffcdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d4aa0f029548a78f08a19707ed83eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep. 10/10] Loss train: 808.77, val: 15169.74; OA train: 985.98, val: 5020.94\n"
     ]
    }
   ],
   "source": [
    "# do epochs\n",
    "while start_epoch < num_epochs:\n",
    "\n",
    "  # training\n",
    "  model, loss_train, oa_train = train_epoch(dl_train_test, model_test, optim_test, device)\n",
    "\n",
    "  # validation\n",
    "  loss_val, oa_val = validate_epoch(dl_val_test, model, device)\n",
    "\n",
    "  # print stats\n",
    "  print('[Ep. {}/{}] Loss train: {:.2f}, val: {:.2f}; OA train: {:.2f}, val: {:.2f}'.format(\n",
    "      start_epoch+1, num_epochs,\n",
    "      loss_train, loss_val,\n",
    "      100*oa_train, 100*oa_val\n",
    "  ))\n",
    "\n",
    "  # save model\n",
    "  start_epoch += 1\n",
    "  save_model(model, start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deef830904124566a24eaae1ca08bf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx_val', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_plot = model\n",
    "\n",
    "val_df = CanopyDataset(split='validation')\n",
    "#train_df = CanopyDataset(split='train', transforms=None)\n",
    "\n",
    "from ipywidgets import interact\n",
    "@interact(idx_val=range(len(val_df)))\n",
    "def plot_sample(idx_val=0):\n",
    "    train_img, train_label = val_df[idx_val]\n",
    "    train_img = train_img.to(torch.float32).to('cuda')\n",
    "    \n",
    "\n",
    "    #data = data.to(torch.float32)   # to match weights of model\n",
    "    #target = target.to(torch.float32) # to match data of model\n",
    "\n",
    "    model_plot.train(False)\n",
    "    # as model expects batch number\n",
    "    train_img = model_plot(train_img.unsqueeze(0))\n",
    "    #model(image_valid.unsqueeze(0))\n",
    "\n",
    "    f, ax = plt.subplots(1,2, figsize=(6,6))\n",
    "    ax = ax.flatten()\n",
    "    img = ax[0].imshow(train_img.cpu().detach())      # conversion to be able to plot\n",
    "    plt.colorbar(img)\n",
    "    ax[0].set_title(\"Train image\")\n",
    "\n",
    "    img = ax[1].imshow(train_label)\n",
    "    plt.colorbar(img)\n",
    "    ax[1].set_title(\"Train label\")\n",
    "    plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPEO",
   "language": "python",
   "name": "ipeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
